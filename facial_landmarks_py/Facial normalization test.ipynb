{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a578e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import math\n",
    "# import face_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be77408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.landmark_util import extract_landmarks_media_pipe\n",
    "from scipy import signal\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee642b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████▉| 716/717.0 [00:25<00:00, 27.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# extract_landmarks_media_pipe(\"rolling_in_the_deep_1.mp4\",\n",
    "#                                  \"F:/MASC/Motion_paint/example_videos\", save_annotated_video=True)\n",
    "extract_landmarks_media_pipe(\"Ps1_phonecam.mp4\",\n",
    "                                 \"F:\\\\MASC\\\\Jali_sing\\\\Revision\\\\validation\\\\faceware session Yannis\\\\Oh Canada\\\\\", save_annotated_video=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c2ec85",
   "metadata": {},
   "source": [
    "# Input block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc054684",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmPath = \"F:/MASC/Motion_paint/example_videos/rolling_in_the_deep_1/raw_mediapipe_landmark.npy\"\n",
    "videoPath = \"F:/MASC/Motion_paint/example_videos/rolling_in_the_deep_1.mp4\"\n",
    "\n",
    "# lmPath = \"/Volumes/EVAN_DISK/MASC/Motion_paint/example_videos/Child_in_time_2/raw_mediapipe_landmark.npy\"\n",
    "# lmPath = \"E:/Facial Feature Motion Clip/rollingInTheDeep/raw_mediapipe_landmark.npy\"\n",
    "# lmPath = \"/Volumes/KINGSTON/csc2521/raw_mediapipe_landmark.npy\"\n",
    "# outputPath = \"/Volumes/EVAN_DISK/emp/child_in_time_motion.json\"\n",
    "outputPath = \"C:/Users/evansamaa/Desktop/Motion_Paint/facial_landmarks_py/data/motion.json\"\n",
    "rotation_output_path = \"C:/Users/evansamaa/Desktop/Motion_Paint/facial_landmarks_py/data/Rot_motion.json\"\n",
    "# info from video\n",
    "t_segment = [0, 169]\n",
    "t_ref = 0\n",
    "# info of target animation\n",
    "start = 0\n",
    "fps = 30\n",
    "min_cutoff = 0.0001\n",
    "beta = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d052c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mediaPipeMapping.json\", \"r\") as f:\n",
    "    maping = json.load(f)\n",
    "\n",
    "staticLandmarkIndices = maping[\"nose\"][\"dorsum\"]+maping[\"nose\"][\"tipLower\"]+maping[\"additional_anchors\"]\n",
    "full_boundary_anchor = maping[\"face_anchors\"]\n",
    "keypointIndicies = maping[\"nose\"][\"dorsum\"]+maping[\"nose\"][\"tipLower\"]+maping[\"additional_anchors\"]+maping[\"brow\"][\"rightLower\"]+maping[\"brow\"][\"rightUpper\"]+maping[\"brow\"][\"leftUpper\"]+maping[\"brow\"][\"leftLower\"]+maping[\"eye\"][\"right\"]+maping[\"eye\"][\"left\"]+maping[\"lips\"][\"inner\"]+maping[\"lips\"][\"outer\"]\n",
    "data = np.load(lmPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e005d51",
   "metadata": {},
   "source": [
    "### Rotation algorithm from http://web.stanford.edu/class/cs273/refs/umeyama.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10974e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rotation(X, Y):\n",
    "    # the algorithm uses X and Y notation, where the input dimension should be (M x N)\n",
    "    # where M is the number of dimension and N is the number of points. the output is\n",
    "    # R, c, t, where they satisfies min_{R, c, t} ||(c*R*X+t) - Y||^2\n",
    "    mu_x = X.mean(axis=1)\n",
    "    mu_y = Y.mean(axis=1)\n",
    "    rho2_x = X.var(axis=1).sum()\n",
    "    rho2_y = Y.var(axis=1).sum()\n",
    "    cov_xy = 1.0 / X.shape[1] * (Y-np.expand_dims(mu_y, axis=1))@(X-np.expand_dims(mu_x, axis=1)).T\n",
    "    # SVD on the covariance matrix\n",
    "    U, D, V_T = np.linalg.svd(cov_xy)\n",
    "    D = np.diag(D)\n",
    "    # prepare sign flipping matrix S, which need to be altered at some point\n",
    "    S = np.identity(3)\n",
    "    # update matrix S based on the rank of cov_xy\n",
    "    if np.linalg.matrix_rank(cov_xy) >= X.shape[0]-1:\n",
    "        if (np.linalg.det(cov_xy) < 0):\n",
    "            S[-1,-1] = -1 \n",
    "    else:\n",
    "        det_U = np.linalg.det(U)\n",
    "        det_V = np.linalg.det(V_T)\n",
    "        if (det_U * det_V < 0):\n",
    "            S[-1,-1] = -1  \n",
    "    # compute rotation and scale and translation\n",
    "    R = U@S@V_T\n",
    "    c = (1.0 / rho2_x) * np.trace(D @ S)\n",
    "    t = mu_y - c * R @ mu_x\n",
    "    # X_prime = c * R @ frame_i.T + np.expand_dims(t, 1)\n",
    "    # X_prime = rotated_frame_i.T\n",
    "    return R, c, np.expand_dims(t, 1)\n",
    "def rotateToNeutral(neutralPose, data, staticIndices, returnRotation=False):\n",
    "    # neturalPose should be a numpy array of shape (N, M)\n",
    "    # data should be a numpy array of shape (T, N, M)\n",
    "    # staticIndices should be a list of integers \n",
    "    outData = np.zeros(data.shape)\n",
    "    R_out = []\n",
    "    for i in range(0, data.shape[0]):\n",
    "        frame_t = data[i,staticIndices]\n",
    "        R, c, t = compute_rotation(frame_t.T, neutralPose[staticIndices].T)\n",
    "        if returnRotation:\n",
    "            R_out.append(R)\n",
    "#         print(t)\n",
    "        outData[i] = (c * R @ data[i].T + t).T\n",
    "    if returnRotation:\n",
    "        return outData, R_out\n",
    "    else:\n",
    "        return outData\n",
    "def smoothing_factor(t_e, cutoff):\n",
    "    r = 2 * math.pi * cutoff * t_e\n",
    "    return r / (r + 1)\n",
    "def exponential_smoothing(a, x, x_prev):\n",
    "    return a * x + (1 - a) * x_prev\n",
    "class OneEuroFilter:\n",
    "    def __init__(self, t0, x0, dx0=0.0, min_cutoff=1.0, beta=0.0,\n",
    "                 d_cutoff=1.0):\n",
    "        \"\"\"Initialize the one euro filter.\"\"\"\n",
    "        # The parameters.\n",
    "        self.min_cutoff = float(min_cutoff)\n",
    "        self.beta = float(beta)\n",
    "        self.d_cutoff = float(d_cutoff)\n",
    "        # Previous values.\n",
    "        self.x_prev = float(x0)\n",
    "        self.dx_prev = float(dx0)\n",
    "        self.t_prev = float(t0)\n",
    "\n",
    "    def __call__(self, t, x):\n",
    "        \"\"\"Compute the filtered signal.\"\"\"\n",
    "        t_e = t - self.t_prev\n",
    "        # The filtered derivative of the signal.\n",
    "        a_d = smoothing_factor(t_e, self.d_cutoff)\n",
    "        dx = (x - self.x_prev) / t_e\n",
    "        dx_hat = exponential_smoothing(a_d, dx, self.dx_prev)\n",
    "\n",
    "        # The filtered signal.\n",
    "        cutoff = self.min_cutoff + self.beta * abs(dx_hat)\n",
    "        a = smoothing_factor(t_e, cutoff)\n",
    "        x_hat = exponential_smoothing(a, x, self.x_prev)\n",
    "\n",
    "        # Memorize the previous values.\n",
    "        self.x_prev = x_hat\n",
    "        self.dx_prev = dx_hat\n",
    "        self.t_prev = t\n",
    "        return x_hat\n",
    "def runEuro(t, data):\n",
    "    out = np.zeros(data.shape)\n",
    "    out[0] = data[0]\n",
    "    one_euro_filter = OneEuroFilter(t[0], data[0],min_cutoff=min_cutoff,beta=beta)\n",
    "    for i in range(1, len(t)):\n",
    "        out[i] = one_euro_filter(t[i], data[i])\n",
    "    return out\n",
    "def constrainedOneEuroFilter(data, dataRange, keyFrames):\n",
    "    # data should be a numpy array of shape (n, )\n",
    "    # dataRange should be a list of two element, a starting frame and an ending frame [start, end)\n",
    "    # keyFrames should be a list of keyframes that the model needs is constraint to\n",
    "    \n",
    "    # construct partitions of the signal\n",
    "    dataPartitions = []\n",
    "    start = 0\n",
    "    end = dataRange[1] - dataRange[0]\n",
    "    for i in range(0, len(keyFrames)):\n",
    "        kf = keyFrames[i] - start # conform it to indexing of array\n",
    "        if i == 0:\n",
    "            if (kf>=1):\n",
    "                dataPartitions.append(data[0:kf])\n",
    "        else:\n",
    "            prev_kf = keyFrames[i-1] - start\n",
    "            dataPartitions.append(data[prev_kf:kf])\n",
    "    dataPartitions.append(data[keyFrames[-1] - start:])\n",
    "    out_dataPartition = []\n",
    "    # using 1 euro filter to perform changes\n",
    "    for i in range(0, len(dataPartitions)):\n",
    "        if i < len(dataPartitions)-1:\n",
    "            forward = dataPartitions[i]\n",
    "            backward = np.flip(dataPartitions[i])\n",
    "            \n",
    "            t = np.arange(0, forward.shape[0])\n",
    "            alpha = np.arange(forward.shape[0], 0, -1)/forward.shape[0]\n",
    "#             plt.plot(backward)\n",
    "            forward = runEuro(t, forward) * alpha\n",
    "            backward = np.flip(runEuro(t, backward) * alpha)\n",
    "        \n",
    "            out_dataPartition.append(forward + backward)\n",
    "        else:\n",
    "            forward = dataPartitions[i]\n",
    "            t = np.arange(0, forward.shape[0])\n",
    "            out_dataPartition.append(runEuro(t, forward))\n",
    "    return np.concatenate(out_dataPartition)\n",
    "def outputToFile(path, arr, fps, start):\n",
    "    # the input should be in the form of a 2D array with shape [n, ]\n",
    "    arr_length = arr.shape[0]\n",
    "    dt = 1.0 / fps\n",
    "    t_arr = np.arange(0, arr_length) * dt + start\n",
    "    t_arr = t_arr.tolist()\n",
    "    arr = arr / arr.max()\n",
    "    v_arr = arr.tolist()\n",
    "    \n",
    "    output = {\"t\": t_arr, \"v\": v_arr}\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output, f)\n",
    "    return\n",
    "min_cutoff = 0.0001\n",
    "beta = 5\n",
    "t_ref = 0\n",
    "dataSegment = data[t_segment[0]:t_segment[1]]\n",
    "ref_frame = data[t_ref]\n",
    "dataSegment = rotateToNeutral(ref_frame, dataSegment, staticLandmarkIndices)\n",
    "leftBrowIndices = maping[\"brow\"][\"leftUpper\"]+list(reversed(maping[\"brow\"][\"leftLower\"]))+maping[\"brow\"][\"rightUpper\"]+maping[\"brow\"][\"rightLower\"]\n",
    "leftBrowDeviation = np.sqrt(np.square(dataSegment[:,leftBrowIndices]-dataSegment[t_ref:t_ref+1,leftBrowIndices])[:,:,0:2].sum(axis=2).mean(1))\n",
    "out = constrainedOneEuroFilter(leftBrowDeviation, t_segment, [t_ref, -1])\n",
    "plt.plot(out)\n",
    "plt.plot(leftBrowDeviation)\n",
    "# outputToFile(outputPath, out, fps, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282abc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i=35\n",
    "staticLandmarkIndices = maping[\"nose\"][\"dorsum\"]+maping[\"nose\"][\"tipLower\"]+maping[\"additional_anchors\"]\n",
    "normlalized_data = rotateToNeutral(data[0], data, staticLandmarkIndices)\n",
    "plt.scatter(data[i, staticLandmarkIndices, 0], -data[i, staticLandmarkIndices,1], label=\"frame_i\")\n",
    "plt.scatter(normlalized_data[i, staticLandmarkIndices, 0], -normlalized_data[i, staticLandmarkIndices,1], label=\"normalized frame_i\")\n",
    "plt.scatter(data[0, staticLandmarkIndices, 0], -data[0, staticLandmarkIndices,1], marker=\"x\", label=\"reference frame\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e4352c",
   "metadata": {},
   "source": [
    "# 1.2 quantitatively testing the normalization (the more points that are used the more likely there won't be as much warping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5cc562",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "staticLandmarkIndices1 = maping[\"nose\"][\"dorsum\"]+maping[\"nose\"][\"tipLower\"]+maping[\"additional_anchors\"]\n",
    "staticLandmarkIndices2 = maping[\"eye\"][\"static\"]+maping[\"nose\"][\"dorsum\"]+maping[\"nose\"][\"tipLower\"]\n",
    "staticLandmarkIndices3 = maping[\"nose\"][\"dorsum\"]+maping[\"nose\"][\"tipLower\"]\n",
    "staticLandmarkIndicesAll = maping[\"nose\"][\"dorsum\"]+maping[\"nose\"][\"tipLower\"]+maping[\"eye\"][\"static\"]+maping[\"additional_anchors\"]\n",
    "# fitting using the nose and chind data\n",
    "normlalized_data = rotateToNeutral(data[0], data, staticLandmarkIndices1)\n",
    "fitting_error = normlalized_data[:, staticLandmarkIndicesAll] - data[0, staticLandmarkIndicesAll]\n",
    "fitting_error = np.square(fitting_error).sum(axis=2).sum(axis=1)\n",
    "plt.plot(fitting_error, label=\"nose and chin\")\n",
    "# fitting using the nose and eye data\n",
    "normlalized_data = rotateToNeutral(data[0], data, staticLandmarkIndices2)\n",
    "fitting_error = normlalized_data[:, staticLandmarkIndicesAll] - data[0, staticLandmarkIndicesAll]\n",
    "fitting_error = np.square(fitting_error).sum(axis=2).sum(axis=1)\n",
    "plt.plot(fitting_error, label=\"nose and eyes\")\n",
    "# fitting using nose only\n",
    "normlalized_data = rotateToNeutral(data[0], data, staticLandmarkIndices3)\n",
    "fitting_error = normlalized_data[:, staticLandmarkIndicesAll] - data[0, staticLandmarkIndicesAll]\n",
    "fitting_error = np.square(fitting_error).sum(axis=2).sum(axis=1)\n",
    "plt.plot(fitting_error, label=\"nose Only\")\n",
    "# fitting using nose, eye, chin data\n",
    "normlalized_data = rotateToNeutral(data[0], data, staticLandmarkIndicesAll)\n",
    "fitting_error = normlalized_data[:, staticLandmarkIndicesAll] - data[0, staticLandmarkIndicesAll]\n",
    "fitting_error = np.square(fitting_error).sum(axis=2).sum(axis=1)\n",
    "plt.plot(fitting_error, label=\"everything\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573e2234",
   "metadata": {},
   "source": [
    "This just shows that the more landmarks the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029117ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normlalized_data = rotateToNeutral(ref_frame, data, staticLandmarkIndices) \n",
    "normlalized_data = np.where(np.isnan(normlalized_data), normlalized_data[0, 0, 0], normlalized_data)\n",
    "x_max = normlalized_data[:, :, 0].max()\n",
    "y_max = (-normlalized_data[:, :, 1]).max()\n",
    "x_min = normlalized_data[:, :, 0].min()\n",
    "y_min = (-normlalized_data[:, :, 1]).min()\n",
    "\n",
    "plt.scatter(normlalized_data[0, keypointIndicies, 0], -normlalized_data[0, keypointIndicies, 1])\n",
    "plt.scatter([x_min, y_min], [x_max, y_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53630aa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.animation as animation\n",
    "def display_landmark(landmark_arr, fps):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_tight_layout(True)\n",
    "    x_max = landmark_arr[:, :, 0].max()\n",
    "    y_max = landmark_arr[:, :, 1].max()\n",
    "    x_min = landmark_arr[:, :, 0].min()\n",
    "    y_min = landmark_arr[:, :, 1].min()\n",
    "    y_range = np.abs(y_max-y_min)\n",
    "    x_range = np.abs(x_max-x_min)\n",
    "    \n",
    "    \n",
    "    def update(i):\n",
    "        label = 'timestep {0}'.format(i)\n",
    "        # Update the line and the axes (with a new xlabel). Return a tuple of\n",
    "        # \"artists\" that have to be redrawn for this frame.\n",
    "        landmark_arr_i = landmark_arr[i]\n",
    "        print(i)\n",
    "        fig.clf()\n",
    "        ax = plt.scatter(landmark_arr_i[:, 0], -landmark_arr_i[:, 1])\n",
    "        ax = plt.scatter([x_min-x_range/10, x_max+x_range/10], [-y_min+y_range/10, -y_max-y_range/10])\n",
    "        return ax\n",
    "    anim = FuncAnimation(fig, update, frames=np.arange(0, landmark_arr.shape[0]), interval=fps)\n",
    "    f = r\"animation.avi\" \n",
    "    writervideo = animation.FFMpegWriter(fps=25)\n",
    "    anim.save(f, writer=writervideo)\n",
    "\n",
    "normlalized_data = rotateToNeutral(ref_frame, data, staticLandmarkIndices)    \n",
    "# display_landmark(normlalized_data[0:10, keypointIndicies], 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8ad39",
   "metadata": {},
   "source": [
    "# 2. Testing methods to compute contour changes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ea575c",
   "metadata": {},
   "source": [
    "### 2.1a General contour information, translation, whole video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313abe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "leftBrowIndices = maping[\"brow\"][\"leftUpper\"]+maping[\"brow\"][\"leftLower\"]\n",
    "nose_indices = maping[\"nose\"][\"dorsum\"]+maping[\"nose\"][\"tip\"]\n",
    "leftBrowData = normlalized_data[:,leftBrowIndices]-normlalized_data[0:1,leftBrowIndices]\n",
    "\n",
    "# leftBrowPositionData = leftBrowData.min(axis=1)\n",
    "# plt.plot(leftBrowPositionData[:,1], label=\"min\")\n",
    "# leftBrowPositionData = leftBrowData.max(axis=1)\n",
    "# plt.plot(leftBrowPositionData[:,1], label=\"max\")\n",
    "leftBrowPositionData = np.square(leftBrowData-leftBrowData[0:1]).mean(axis=1)\n",
    "plt.plot(leftBrowPositionData[:,1], label=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5523e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "leftBrowIndices_loop = maping[\"brow\"][\"leftUpper\"]+list(reversed(maping[\"brow\"][\"leftLower\"]))\n",
    "leftBrowData = normlalized_data[:,leftBrowIndices_loop]\n",
    "refFrame = leftBrowData[0]\n",
    "f_0 = turning_feature_vector(refFrame[:, 0:2])\n",
    "dist = np.zeros((normlalized_data.shape[0], ))\n",
    "for i in range(0, normlalized_data.shape[0]):\n",
    "    dist[i] = np.square(f_0-turning_feature_vector(leftBrowData[i, :, 0:2])).sum()\n",
    "plt.plot(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c4854",
   "metadata": {},
   "source": [
    "### 2.1b General contour information, translation, segment of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8fa28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_segment = [0, 168]\n",
    "t_ref = 159\n",
    "staticLandmarkIndices = maping[\"nose\"][\"dorsum\"]+maping[\"nose\"][\"tipLower\"]+maping[\"additional_anchors\"]\n",
    "leftBrowIndices = maping[\"brow\"][\"leftUpper\"]+maping[\"brow\"][\"leftLower\"]\n",
    "nose_indices = maping[\"nose\"][\"dorsum\"]+maping[\"nose\"][\"tip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a897049b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataSegment = data[t_segment[0]:t_segment[1]]\n",
    "ref_frame = data[t_ref]\n",
    "dataSegment = rotateToNeutral(dataSegment[0], dataSegment, staticLandmarkIndices)\n",
    "leftBrowDistanceFromNeutral = np.square(dataSegment[:,leftBrowIndices]-dataSegment[t_ref:t_ref+1,leftBrowIndices])[:,:,0:2].sum(axis=2)\n",
    "leftBrowDistanceFromNeutral = np.sqrt(leftBrowDistanceFromNeutral.mean(axis=1))\n",
    "smoothed_signal = signal.savgol_filter(leftBrowDistanceFromNeutral, min(5, np.floor(leftBrowDistanceFromNeutral.shape[0]/2)*2-1), 1)\n",
    "plt.plot(leftBrowDistanceFromNeutral[:], label=\"raw\")\n",
    "plt.plot(smoothed_signal, label=\"savgol\")\n",
    "t = np.arange(0, dataSegment.shape[0])\n",
    "x_hat = np.zeros_like(leftBrowDistanceFromNeutral)\n",
    "x_hat[0] = leftBrowDistanceFromNeutral[0]\n",
    "one_euro_filter = OneEuroFilter(t[0], leftBrowDistanceFromNeutral[0],min_cutoff=min_cutoff,beta=beta)\n",
    "for i in range(1, len(t)):\n",
    "    x_hat[i] = one_euro_filter(t[i], leftBrowDistanceFromNeutral[i])\n",
    "plt.plot(x_hat, label=\"1euro\")\n",
    "# x_hat = constrainedOneEuroFilter(leftBrowDistanceFromNeutral, t_segment, [t_ref])\n",
    "# plt.plot(x_hat, label=\"2euro\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93c37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12e22c7c",
   "metadata": {},
   "source": [
    "# 2.2 General contour information, shape contour, segment of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b4b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_feature_vector(input_contour):\n",
    "    input_contour_tiled = np.tile(input_contour, [1, input_contour.shape[0]])\n",
    "    input_contour_T_tiled = np.tile(input_contour.reshape(input_contour.shape[0]*input_contour.shape[1],1).T, [input_contour.shape[0], 1])\n",
    "    relative_dif = input_contour_tiled - input_contour_T_tiled\n",
    "    relative_dif = relative_dif.reshape((input_contour.shape[0]*input_contour.shape[0],3))\n",
    "    relative_dif = np.linalg.norm(relative_dif, axis=1)\n",
    "    return relative_dif\n",
    "def contour_t_comparison(input_contour_set, reference_frame):\n",
    "    f0 = relative_feature_vector(reference_frame)\n",
    "    out = np.zeros((input_contour_set.shape[0], ))\n",
    "    for i in range(0, input_contour_set.shape[0]):\n",
    "        fi = relative_feature_vector(input_contour_set[i])\n",
    "        np.square(f0-fi).sum()\n",
    "        out[i] = np.square(f0-fi).sum()\n",
    "    return out\n",
    "def outputToFile(path, arr, fps, start, angle=False):\n",
    "    # the input should be in the form of a 2D array with shape [n, ]\n",
    "    arr_length = arr.shape[0]\n",
    "    dt = 1.0 / fps\n",
    "    t_arr = np.arange(0, arr_length) * dt + start\n",
    "    t_arr = t_arr.tolist()\n",
    "    if not angle:\n",
    "        arr = arr / arr.max()\n",
    "    v_arr = arr.tolist()\n",
    "    \n",
    "    output = {\"t\": t_arr, \"v\": v_arr}\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output, f)\n",
    "    return\n",
    "# outputToFile(outputPath, x_hat, fps, start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f50548f",
   "metadata": {},
   "source": [
    "# 2.3 General contour information, turning angle distance, segment of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b837d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turning_feature_vector(input_contour):\n",
    "    # input contour should be shaped (n, 2), with m being the number of 2D dimensions X and Y\n",
    "    v1 = np.zeros((input_contour.shape[0]+1, input_contour.shape[1]))\n",
    "    v1[1:] = input_contour\n",
    "    v1[0] = input_contour[-1]\n",
    "    v2 = np.zeros((input_contour.shape[0]+1, input_contour.shape[1]))\n",
    "    v2[0:-1] = input_contour\n",
    "    v = v2-v1\n",
    "    theta = np.arctan2(v[:, 0], v[:, 1])[0:-1]\n",
    "#     print(theta)\n",
    "    return theta\n",
    "leftBrowIndices_loop = maping[\"brow\"][\"leftUpper\"]+list(reversed(maping[\"brow\"][\"leftLower\"]))\n",
    "leftBrowData = dataSegment[:,leftBrowIndices_loop]\n",
    "refFrame = leftBrowData[0]\n",
    "f_0 = turning_feature_vector(refFrame[:, 0:2])\n",
    "dist = np.zeros((dataSegment.shape[0], ))\n",
    "for i in range(0, dataSegment.shape[0]):\n",
    "    dist[i] = np.square(f_0-turning_feature_vector(leftBrowData[i, :, 0:2])).sum()\n",
    "plt.plot(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5174e0da",
   "metadata": {},
   "source": [
    "# 3. Use shear to correct landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSheerMat(dimensions=3):\n",
    "    out = []\n",
    "    if dimensions == 3:\n",
    "        sheer_x_y = np.eye(3)\n",
    "        sheer_x_y[1,0] = 1\n",
    "        sheer_x_z = np.eye(3)\n",
    "        sheer_x_z[2,0] = 1\n",
    "        \n",
    "        sheer_y_x = np.eye(3)\n",
    "        sheer_y_x[0,1] = 1\n",
    "        sheer_y_z = np.eye(3)\n",
    "        sheer_y_z[2,1] = 1\n",
    "        \n",
    "        sheer_z_x = np.eye(3)\n",
    "        sheer_z_x[0,2] = 1\n",
    "        sheer_z_y = np.eye(3)\n",
    "        sheer_z_y[1,2] = 1\n",
    "        \n",
    "        stretch_x = np.eye(3)\n",
    "        stretch_x[0, 0] = 2\n",
    "        \n",
    "        stretch_y = np.eye(3)\n",
    "        stretch_y[1, 1] = 2\n",
    "        \n",
    "        stretch_z = np.eye(3)\n",
    "        stretch_z[2, 2] = 2\n",
    "        \n",
    "        \n",
    "        out = [sheer_x_y, sheer_x_z, sheer_y_x, sheer_y_z, sheer_z_x, sheer_z_y, stretch_x, stretch_y, stretch_z]\n",
    "    return out\n",
    "        \n",
    "\n",
    "def shearBasis(landmarks, anchor, transformations):\n",
    "    # this function expect pointCloud to be in the shape of [3, n]\n",
    "    # anchor should be the shape [3, 1]\n",
    "    # return a set of differential blendshapes that represents the pointCloud, centered\n",
    "    # around the anchor, sheared in all 6 directions.\n",
    "    # returns a list of arrays, with shape of [3, n], these are differential blendshapes\n",
    "    \n",
    "    out = []\n",
    "    centered_landmarks = landmarks - anchor\n",
    "    for trans in transformations:\n",
    "        out.append((trans @ centered_landmarks + anchor - landmarks))\n",
    "    return out, landmarks\n",
    "def inverseIK(blendshapes, baseshape, target, indices):\n",
    "    # baseshape and target should both in shape of [3, n]\n",
    "    # blendshape is a list of arrays with shape [3, n]\n",
    "    \n",
    "    diff = (target[:, indices] - baseshape[:, indices]).reshape([target.shape[0]*len(indices), 1])\n",
    "    B = []\n",
    "    for i in range(0, len(blendshapes)):\n",
    "        mat = blendshapes[i][:, indices].reshape([target.shape[0]*len(indices), ])\n",
    "        B.append(np.expand_dims(mat, axis=0))\n",
    "    B = np.concatenate(B, axis=0)\n",
    "    w = np.linalg.inv(B@B.T)@B@diff\n",
    "    return w\n",
    "t = 70\n",
    "def shearNormalization(data, neutral_frame, shear_landmarkSet, rotation=True, rotation_landmarkset=None):\n",
    "    data_0 = neutral_frame\n",
    "    out_data = []\n",
    "    basis_transformation = getSheerMat()\n",
    "    for t in range(0, len(data)):\n",
    "        data_1 = data[t]\n",
    "        shearCenter = [4]\n",
    "        if rotation:\n",
    "            R, c, t = compute_rotation(data_1[rotation_landmarkset].T, data_0[rotation_landmarkset].T)\n",
    "            norm_data_1 = (c*R @ data_1.T+t).T\n",
    "        else:\n",
    "            norm_data_1 = data_1\n",
    "        # do the shear transformtions\n",
    "        basis, neutral = shearBasis(norm_data_1.T, norm_data_1[shearCenter].T, basis_transformation)\n",
    "        # basis and neutralis that of the entire mesh\n",
    "        w = inverseIK(basis, neutral, data_0.T, shear_landmarkSet)\n",
    "        sheared_data_1 = neutral\n",
    "        for i in range(0, len(basis)):\n",
    "            sheared_data_1 = sheared_data_1 + w[i] * basis[i]\n",
    "        sheared_data_1 = sheared_data_1.T\n",
    "        out_data.append(np.expand_dims(sheared_data_1, axis=0))\n",
    "    out_data = np.concatenate(out_data, axis=0)\n",
    "    return out_data\n",
    "def iterativeNormalization(data, neutral_frame, rotation_landmarkset, sheer_landmarkset):\n",
    "    out_data = shearNormalization(data, neutral_frame, sheer_landmarkset, rotation=True, rotation_landmarkset=rotation_landmarkset)\n",
    "    out_data = shearNormalization(out_data, neutral_frame, sheer_landmarkset, rotation=True, rotation_landmarkset=rotation_landmarkset)\n",
    "    out_data = shearNormalization(out_data, neutral_frame, sheer_landmarkset, rotation=True, rotation_landmarkset=rotation_landmarkset)\n",
    "    return out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67644c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 90\n",
    "iterativenormData = iterativeNormalization(dataSegment, ref_frame, staticLandmarkIndices, staticLandmarkIndices)\n",
    "shearedData = shearNormalization(data, data[0], staticLandmarkIndices, rotation_landmarkset=staticLandmarkIndices)\n",
    "sheared_data_1  = shearedData[i]\n",
    "# plt.scatter(sheared_data_1[staticLandmarkIndices, 0], -sheared_data_1[staticLandmarkIndices, 1])\n",
    "plt.scatter(iterativenormData[i][staticLandmarkIndices, 0], -iterativenormData[i][staticLandmarkIndices, 1])\n",
    "plt.scatter(data[0][staticLandmarkIndices, 0], -data[0][staticLandmarkIndices, 1])\n",
    "plt.scatter([0.475, 0.725], [-0.7, -0.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e6ca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "staticLandmarkIndices_alt = maping[\"nose\"][\"dorsum\"]+maping[\"nose\"][\"tipLower\"]+[127, 356, 132, 361]\n",
    "\n",
    "# iterative_normalized_data_alt = iterativeNormalization(data, data[0], staticLandmarkIndices_alt, staticLandmarkIndices_alt)\n",
    "\n",
    "iterative_normalized_data = iterativeNormalization(data[0:750], data[0], staticLandmarkIndices, staticLandmarkIndices)\n",
    "shear_rotated_data = shearNormalization(data[0:750], data[0], staticLandmarkIndices, rotation=True, rotation_landmarkset=staticLandmarkIndices)\n",
    "rotated_data = rotateToNeutral(data[0], data[0:750], staticLandmarkIndices)\n",
    "fitting_error = shear_rotated_data[:, staticLandmarkIndices] - data[0, staticLandmarkIndices]\n",
    "fitting_error = np.square(fitting_error).sum(axis=2).sum(axis=1)\n",
    "plt.plot(fitting_error, label=\"rotation and shear\")\n",
    "fitting_error = rotated_data[:, staticLandmarkIndices] - data[0, staticLandmarkIndices]\n",
    "fitting_error = np.square(fitting_error).sum(axis=2).sum(axis=1)\n",
    "plt.plot(fitting_error, label=\"rotation only\")\n",
    "fitting_error = iterative_normalized_data[:, staticLandmarkIndices] - data[0, staticLandmarkIndices]\n",
    "fitting_error = np.square(fitting_error).sum(axis=2).sum(axis=1)\n",
    "plt.plot(fitting_error, label=\"iterative rotation and shear\")\n",
    "# fitting_error = iterative_normalized_data_alt[:, staticLandmarkIndices] - data[0, staticLandmarkIndices]\n",
    "# fitting_error = np.square(fitting_error).sum(axis=2).sum(axis=1)\n",
    "# plt.plot(fitting_error, label=\"iterative rotation and shear alt\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0ebc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dataSegment = data[t_segment[0]:t_segment[1]]\n",
    "ref_frame = data[0]\n",
    "dataSegment = iterativeNormalization(dataSegment, ref_frame, staticLandmarkIndices, staticLandmarkIndices)\n",
    "# leftBrowDistanceFromNeutral = np.square(dataSegment[:,leftBrowIndices]-dataSegment[t_ref:t_ref+1,leftBrowIndices])[:,:,0:2].sum(axis=2)\n",
    "leftBrowDistanceFromNeutral = np.square(dataSegment[:,leftBrowIndices,1:2]-dataSegment[t_ref:t_ref+1,leftBrowIndices,1:2])[:,:,0:2].sum(axis=2)\n",
    "leftBrowDistanceFromNeutral = np.sqrt(leftBrowDistanceFromNeutral.mean(axis=1))\n",
    "smoothed_signal = signal.savgol_filter(leftBrowDistanceFromNeutral, min(5, np.floor(leftBrowDistanceFromNeutral.shape[0]/2)*2-1), 1)\n",
    "plt.plot(leftBrowDistanceFromNeutral[:], label=\"raw\")\n",
    "plt.plot(smoothed_signal, label=\"savgol\")\n",
    "t = np.arange(0, dataSegment.shape[0])\n",
    "x_hat = np.zeros_like(leftBrowDistanceFromNeutral)\n",
    "x_hat[0] = leftBrowDistanceFromNeutral[0]\n",
    "one_euro_filter = OneEuroFilter(t[0], leftBrowDistanceFromNeutral[0],min_cutoff=min_cutoff,beta=beta)\n",
    "for i in range(1, len(t)):\n",
    "    x_hat[i] = one_euro_filter(t[i], leftBrowDistanceFromNeutral[i])\n",
    "plt.plot(x_hat, label=\"1euro\")\n",
    "plt.legend()\n",
    "outputToFile(outputPath, x_hat, fps, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffded8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSegment = data[t_segment[0]:t_segment[1]]\n",
    "ref_frame = data[0]\n",
    "dataSegment = rotateToNeutral(dataSegment[0], dataSegment, staticLandmarkIndices)\n",
    "leftBrowDistanceFromNeutral = np.square(dataSegment[:,leftBrowIndices,1:2]-dataSegment[t_ref:t_ref+1,leftBrowIndices,1:2])[:,:,0:2].sum(axis=2)\n",
    "leftBrowDistanceFromNeutral = np.sqrt(leftBrowDistanceFromNeutral.mean(axis=1))\n",
    "smoothed_signal = signal.savgol_filter(leftBrowDistanceFromNeutral, min(5, np.floor(leftBrowDistanceFromNeutral.shape[0]/2)*2-1), 1)\n",
    "plt.plot(leftBrowDistanceFromNeutral[:], label=\"raw\")\n",
    "plt.plot(smoothed_signal, label=\"savgol\")\n",
    "t = np.arange(0, dataSegment.shape[0])\n",
    "x_hat = np.zeros_like(leftBrowDistanceFromNeutral)\n",
    "x_hat[0] = leftBrowDistanceFromNeutral[0]\n",
    "one_euro_filter = OneEuroFilter(t[0], leftBrowDistanceFromNeutral[0],min_cutoff=min_cutoff,beta=beta)\n",
    "for i in range(1, len(t)):\n",
    "    x_hat[i] = one_euro_filter(t[i], leftBrowDistanceFromNeutral[i])\n",
    "plt.plot(x_hat, label=\"1euro\")\n",
    "# x_hat = constrainedOneEuroFilter(leftBrowDistanceFromNeutral, t_segment, [t_ref])\n",
    "# plt.plot(x_hat, label=\"2euro\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29532823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 20\n",
    "iterativenormData = iterativeNormalization(dataSegment, ref_frame, staticLandmarkIndices, staticLandmarkIndices)\n",
    "shearedData = shearNormalization(data, data[0], staticLandmarkIndices, rotation_landmarkset=staticLandmarkIndices)\n",
    "rotated_data = rotateToNeutral(data[0], data, staticLandmarkIndices)\n",
    "sheared_data_1  = shearedData[i]\n",
    "# plt.scatter(sheared_data_1[staticLandmarkIndices, 0], -sheared_data_1[staticLandmarkIndices, 1])\n",
    "# plt.scatter(iterativenormData[i][staticLandmarkIndices, 0], -iterativenormData[i][staticLandmarkIndices, 1], label=\"rotation and shear\")\n",
    "plt.scatter(rotated_data[i][staticLandmarkIndices, 0], -rotated_data[i][staticLandmarkIndices, 1], label=\"rotation only\")\n",
    "plt.scatter(data[0][staticLandmarkIndices, 0], -data[0][staticLandmarkIndices, 1], label=\"reference frame\")\n",
    "plt.scatter([0.475, 0.725], [-0.7, -0.2])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08066bd6",
   "metadata": {},
   "source": [
    "# 3.1 comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68825223",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSegment = data[t_segment[0]:t_segment[1]]\n",
    "ref_frame = data[159]\n",
    "\n",
    "dataSegment = iterativeNormalization(dataSegment, ref_frame, staticLandmarkIndices, staticLandmarkIndices)\n",
    "leftBrowDistanceFromNeutral = np.square(dataSegment[:,leftBrowIndices,1:2]-dataSegment[t_ref:t_ref+1,leftBrowIndices,1:2])[:,:,0:2].sum(axis=2)\n",
    "leftBrowDistanceFromNeutral = np.sqrt(leftBrowDistanceFromNeutral.mean(axis=1))\n",
    "plt.plot(leftBrowDistanceFromNeutral[:], label=\"rotation and shear\")\n",
    "\n",
    "# dataSegment = iterativeNormalization(dataSegment, ref_frame, staticLandmarkIndices, staticLandmarkIndices)\n",
    "# leftBrowDistanceFromNeutral = np.square(dataSegment[:,leftBrowIndices]-dataSegment[t_ref:t_ref+1,leftBrowIndices])[:,:,0:2].sum(axis=2)\n",
    "# leftBrowDistanceFromNeutral = np.sqrt(leftBrowDistanceFromNeutral.mean(axis=1))\n",
    "# plt.plot(leftBrowDistanceFromNeutral[:], label=\"absolute positional difference\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67176f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSegment = data[t_segment[0]:t_segment[1]]\n",
    "ref_frame = data[0]\n",
    "\n",
    "dataSegment = rotateToNeutral(dataSegment[0], dataSegment, staticLandmarkIndices)\n",
    "leftBrowDistanceFromNeutral = np.square(dataSegment[:,leftBrowIndices,1:2]-dataSegment[t_ref:t_ref+1,leftBrowIndices,1:2])[:,:,0:2].sum(axis=2)\n",
    "leftBrowDistanceFromNeutral = np.sqrt(leftBrowDistanceFromNeutral.mean(axis=1))\n",
    "plt.plot(leftBrowDistanceFromNeutral[:], label=\"rotation only\")\n",
    "\n",
    "dataSegment = rotateToNeutral(dataSegment[0], dataSegment, staticLandmarkIndices)\n",
    "leftBrowDistanceFromNeutral = np.square(dataSegment[:,leftBrowIndices]-dataSegment[t_ref:t_ref+1,leftBrowIndices])[:,:,0:2].sum(axis=2)\n",
    "leftBrowDistanceFromNeutral = np.sqrt(leftBrowDistanceFromNeutral.mean(axis=1))\n",
    "plt.plot(leftBrowDistanceFromNeutral[:], label=\"absolute positional difference\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63b13aa",
   "metadata": {},
   "source": [
    "# 4. C HMM implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759c19f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataSegment = data[t_segment[0]:t_segment[1]]\n",
    "Y = dataSegment[:,staticLandmarkIndices,:]\n",
    "Y = Y - Y.mean(axis=1, keepdims=True)\n",
    "Y = Y.reshape((Y.shape[0], len(staticLandmarkIndices) * 3, 1))\n",
    "print(np.sqrt(np.square(Y).sum(axis=1, keepdims=True)).shape)\n",
    "Y = Y / np.sqrt(np.square(Y).sum(axis=1, keepdims=True))\n",
    "\n",
    "S = Y @ Y.transpose((0, 2, 1))\n",
    "S = S.sum(axis=0)\n",
    "eigen_values, eigen_vectors = np.linalg.eig(S)\n",
    "miu = eigen_vectors[:, 0].T\n",
    "miu = miu.reshape((len(staticLandmarkIndices), 3))\n",
    "# plt.scatter(data[0][staticLandmarkIndices, 0], -data[0][staticLandmarkIndices, 1])\n",
    "plt.scatter(miu[:, 0], -miu[:, 1])\n",
    "plt.scatter([-1, 1], [-1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dcc48c",
   "metadata": {},
   "source": [
    "### NSSA Training - eye brows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08041ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "leftBrowIndices = maping[\"brow\"][\"leftUpper\"]+maping[\"brow\"][\"leftLower\"]\n",
    "\n",
    "\n",
    "# noisy signal Y \n",
    "Y = data[t_segment[0]:t_segment[1]]\n",
    "# center Y around mean\n",
    "Y = Y - Y.mean(axis=1, keepdims=True)\n",
    "# compute shape Z\n",
    "Z = iterativeNormalization(Y, Y[59], staticLandmarkIndices, staticLandmarkIndices)\n",
    "Z = Z[:, leftBrowIndices, 0:2] # dimensional reduction to keep only key points, and 2 Dimensions\n",
    "# reshape Z\n",
    "T, N, k = Z.shape\n",
    "# centering matrix C:\n",
    "C = np.eye(N*k) - (np.ones((N*k, 1)) @ np.ones((1, N*k)))/N/k\n",
    "Z_flat = Z.reshape(T, N*k, 1)\n",
    "Z_flat = np.expand_dims(C, axis=0) @ Z_flat\n",
    "Z_flat = Z_flat / np.linalg.norm(Z_flat, axis=1, keepdims=True)\n",
    "V_flat = np.zeros(Z_flat.shape) # tangent space coordinate\n",
    "c_flat = np.zeros(Z_flat.shape) # \n",
    "\n",
    "# compute vt\n",
    "for i in range(1, T):\n",
    "    V_flat[i] = (np.eye(N*k) - Z_flat[i-1] @ Z_flat[i-1].T) @ Z_flat[i]\n",
    "    # obtain the basis matrix\n",
    "    T_z_im1 = (np.eye(N*k) - Z_flat[i-1] @ Z_flat[i-1].T) @ C\n",
    "    U, _, _ = np.linalg.svd(T_z_im1)\n",
    "    c_flat[i] = U.T @ Z_flat[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae326ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute learned AutoRegression matrix parameters\n",
    "V_flat_outer = V_flat  @ V_flat.transpose((0, 2, 1))\n",
    "cov_v = (V_flat_outer[1:].sum(axis=0))/(T-1)\n",
    "R_v =  (V_flat[2:] @ V_flat[1:-1].transpose((0, 2, 1))).sum(axis=0)/(T-2)\n",
    "A = R_v @ np.linalg.inv(cov_v)\n",
    "temp = V_flat[2:] - np.expand_dims(A, 0) @ V_flat[1:-1]\n",
    "cov_n = (temp @ temp.transpose((0, 2, 1))).sum(axis=0)/(T-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5bc63a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v_t = V_flat[1]\n",
    "z_t = Z_flat[1]\n",
    "N_sample = 1\n",
    "for i in range(0, 100):\n",
    "    noise = np.random.multivariate_normal(np.zeros(Z_flat[0, :, 0].shape), cov_n, N_sample)\n",
    "    noise = np.expand_dims(noise, axis=2)\n",
    "    v_t = A @ v_t\n",
    "    z_t = np.sqrt(1 - v_t[k].T @ v_t[k]) * z_t + v_t[k]\n",
    "    z_t_plot = z_t.reshape(Z[0].shape)\n",
    "    plt.scatter(z_t_plot[:, 0], -z_t_plot[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8fac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.det(np.linalg.matrix_power(A, 96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d51341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweigh(samples, observation, iteration=1):\n",
    "   # samples should be of shape [N_sample, dims]\n",
    "   # observation should be of shape [dims, ]\n",
    "    samples = np.expand_dims(samples, axis=1)\n",
    "    observation = np.expand_dims(np.expand_dims(observation, axis=0), axis=2)\n",
    "    weight = samples @ observation[0] / (np.linalg.norm(observation[0:1],axis=1,keepdims=True) * np.linalg.norm(samples, axis=2,keepdims=True))\n",
    "    weight = weight / weight.sum()\n",
    "    for i in range(0, iteration-1):\n",
    "        weight = weight * weight\n",
    "        weight = weight / weight.sum()\n",
    "    v_0 = (samples * weight).sum(axis=0)\n",
    "    return v_0 \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6cc618",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "N_sample = 1000\n",
    "iterations = 10\n",
    "T, K_by_2, _ = Z_flat.shape\n",
    "Z_state = np.zeros(Z_flat.shape)\n",
    "V_state = np.zeros(Z_flat.shape)\n",
    "c_state = np.zeros(Z_flat.shape)\n",
    "\n",
    "################################################\n",
    "#################### t = 0 #####################\n",
    "################################################\n",
    "\n",
    "# generate particles\n",
    "v_sample = np.random.multivariate_normal(np.zeros(Z_flat[0, :, 0].shape), cov_v, N_sample)\n",
    "# obtain the observed shape velocity from shape\n",
    "v_observed = ((np.eye(K_by_2) - Z_flat[0, :] @  Z_flat[0, :].T) @ Z_flat[0, :])[:, 0]\n",
    "# use similarity score to estimate weight\n",
    "v_0 = reweigh(v_sample, v_observed, iterations)\n",
    "# next_sample = np.random.choice(samples, weights) # this allows us to sample from a re-weighted distribution\n",
    "# plt.plot(v_0[:, 0])\n",
    "# plt.plot(v_observed[0, :, 0])\n",
    "Z_state[0] = np.sqrt(1 - v_0 @ v_0.T) * Z_flat[0] + v_0.T\n",
    "V_state[0] = v_0.T\n",
    "\n",
    "# using observed value for Z, V and C\n",
    "Z_state[0] = Z_flat[0]\n",
    "# V_state[0] = (np.eye(K_by_2) - Z_state[0] @ Z_state[0].T) @ Z_flat[0]\n",
    "T_z_im1 = (np.eye(K_by_2) - Z_state[0] @ Z_state[0].T) @ (np.eye(K_by_2) - np.ones((K_by_2, 1)) @ np.ones((1, K_by_2))/K_by_2)\n",
    "U, _, _ = np.linalg.svd(T_z_im1)\n",
    "c_state[0] = U @ Z_state[0]\n",
    "################################################\n",
    "#################### t = 1 #####################\n",
    "################################################\n",
    "for i in range(1, T):\n",
    "    v_sample = np.random.multivariate_normal((A @ V_state[i-1])[:, 0], cov_n, N_sample)\n",
    "    # obtain the observed shape velocity from shape\n",
    "    v_observed = ((np.eye(K_by_2) - Z_state[i-1, :] @  Z_state[i-1, :].T) @ Z_flat[i, :])[:, 0]\n",
    "    # use similarity score to estimate weight\n",
    "    v_0 = reweigh(v_sample, v_observed, iterations)\n",
    "    Z_state[i] = np.sqrt(max(0, 1 - v_0 @ v_0.T)) * Z_flat[i-1] + v_0.T\n",
    "    V_state[i] = v_0.T\n",
    "    T_z_im1 = (np.eye(K_by_2) - Z_state[i-1] @ Z_state[i-1].T) @ (np.eye(K_by_2) - np.ones((K_by_2, 1)) @ np.ones((1, K_by_2))/K_by_2)\n",
    "    U, _, _ = np.linalg.svd(T_z_im1)\n",
    "    c_state[i] = U @ Z_state[i]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0bcabd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 50\n",
    "Z_new = Z_state.reshape(Z.shape)\n",
    "plt.scatter(Z_new[i, :, 0], -Z_new[i, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28b36da",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "N_sample = 1000\n",
    "T, K_by_2, _ = Z_flat.shape\n",
    "Z_state = np.zeros(Z_flat.shape)\n",
    "V_state = np.zeros(Z_flat.shape)\n",
    "c_state = np.zeros(Z_flat.shape)\n",
    "\n",
    "################################################\n",
    "#################### t = 0 #####################\n",
    "################################################\n",
    "\n",
    "# generate particles\n",
    "v_sample = np.random.multivariate_normal(np.zeros(Z_flat[0, :, 0].shape), cov_v, N_sample)\n",
    "v_sample = np.expand_dims(v_sample, axis=1)\n",
    "# obtain the observed shape velocity from shape\n",
    "v_observed = (np.eye(K_by_2) - Z_flat[0, :] @  Z_flat[0, :].T) @ Z_flat[0, :]\n",
    "v_observed = np.expand_dims(v_observed, 0)\n",
    "# use similarity score to estimate weight\n",
    "weight = v_sample @ v_observed[0] / (np.linalg.norm(v_observed[0:1],axis=1,keepdims=True) * np.linalg.norm(v_sample, axis=2,keepdims=True))\n",
    "# normalize weight to 1\n",
    "# weight = np.exp(weight)\n",
    "weight = weight / weight.sum()\n",
    "# compute expected value of shape velocity\n",
    "v_0 = (v_sample * weight).sum(axis=0)\n",
    "# can do more iteration of sampling -> compute expected value if needed\n",
    "# next_sample = np.random.choice(samples, weights) # this allows us to sample from a re-weighted distribution\n",
    "# plt.plot(v_0[:, 0])\n",
    "# plt.plot(v_observed[0, :, 0])\n",
    "Z_state[0] = np.sqrt(1 - v_0 @ v_0.T) * Z_flat[0] + v_0.T\n",
    "V_state[0] = v_0.T\n",
    "\n",
    "# using observed value for Z, V and C\n",
    "Z_state[0] = Z_flat[0]\n",
    "# V_state[0] = (np.eye(K_by_2) - Z_state[0] @ Z_state[0].T) @ Z_flat[0]\n",
    "T_z_im1 = (np.eye(K_by_2) - Z_state[0] @ Z_state[0].T) @ (np.eye(K_by_2) - np.ones((K_by_2, 1)) @ np.ones((1, K_by_2))/K_by_2)\n",
    "U, _, _ = np.linalg.svd(T_z_im1)\n",
    "c_state[0] = U @ Z_state[0]\n",
    "################################################\n",
    "#################### t = 1 #####################\n",
    "################################################\n",
    "\n",
    "v_sample = np.random.multivariate_normal((A @ V_state[0])[:, 0], cov_n, N_sample)\n",
    "v_sample = np.expand_dims(v_sample, axis=1) # shape is (N_sample, 1, N x k)\n",
    "# obtain the observed shape velocity from shape\n",
    "v_observed = (np.eye(K_by_2) - Z_state[0, :] @  Z_state[0, :].T) @ Z_flat[1, :]\n",
    "v_observed = np.expand_dims(v_observed, 0) # shape is (1, N x k ,1)\n",
    "# use similarity score to estimate weight\n",
    "weight = v_sample @ v_observed[0] / (np.linalg.norm(v_observed,axis=1,keepdims=True) * np.linalg.norm(v_sample, axis=2,keepdims=True))\n",
    "# normalize weight to 1\n",
    "# weight = np.exp(weight)\n",
    "weight = weight / weight.sum() \n",
    "# compute expected value of shape velocity\n",
    "v_0 = (v_sample * weight).sum(axis=0)\n",
    "Z_state[1] = np.sqrt(max(0, 1 - v_0 @ v_0.T)) * Z_flat[0] + v_0.T\n",
    "V_state[1] = v_0.T\n",
    "T_z_im1 = (np.eye(K_by_2) - Z_state[0] @ Z_state[0].T) @ (np.eye(K_by_2) - np.ones((K_by_2, 1)) @ np.ones((1, K_by_2))/K_by_2)\n",
    "U, _, _ = np.linalg.svd(T_z_im1)\n",
    "c_state[1] = U @ Z_state[1]\n",
    "\n",
    "################################################\n",
    "#################### t >= 2 ####################\n",
    "################################################\n",
    "\n",
    "for i in range(2, T):\n",
    "    T_z_im1 = (np.eye(K_by_2) - Z_state[i-1] @ Z_state[i-1].T) @ (np.eye(K_by_2) - np.ones((K_by_2, 1)) @ np.ones((1, K_by_2))/K_by_2)\n",
    "    U_im1, _, _ = np.linalg.svd(T_z_im1)\n",
    "    T_z_im2 = (np.eye(K_by_2) - Z_state[i-2] @ Z_state[i-2].T) @ (np.eye(K_by_2) - np.ones((K_by_2, 1)) @ np.ones((1, K_by_2))/K_by_2)\n",
    "    U_im2, _, _ = np.linalg.svd(T_z_im2)\n",
    "    A_c_t = U_im1.T @ A @ U_im2\n",
    "    cov_c_t = U_im1.T @ cov_n @ U_im2\n",
    "    c_sample = np.random.multivariate_normal((A_c_t @ c_state[i-1])[:, 0], cov_c_t, N_sample)\n",
    "    c_sample = np.expand_dims(c_sample, axis=1)\n",
    "    c_observed = U_im1.T @ Z_flat[i, :] \n",
    "    c_observed = np.expand_dims(c_observed, 0)\n",
    "    # use similarity score to estimate weight\n",
    "    weight = c_sample @ c_observed[0] / (np.linalg.norm(c_observed,axis=1,keepdims=True) * np.linalg.norm(c_sample, axis=2,keepdims=True))\n",
    "    # normalize weight to 1\n",
    "#     weight = np.exp(weight)\n",
    "    weight = weight / weight.sum()\n",
    "    c_t = (c_sample * weight).sum(axis=0)\n",
    "    c_state[i] = c_t.T\n",
    "    \n",
    "    V_state[i] = U_im1 @ c_state[i]\n",
    "    Z_state[i] = np.sqrt(1 - V_state[i].T @ V_state[i]) * Z_state[i-1] + V_state[i]\n",
    "    \n",
    "    plt.show()\n",
    "    z_t_plot = Z_state[i].reshape(Z[0].shape)\n",
    "    plt.scatter(z_t_plot[:, 0], -z_t_plot[:, 1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c2702c",
   "metadata": {},
   "source": [
    "# 5. get rotation angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d362d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as Rot\n",
    "\n",
    "min_cutoff = 0.03\n",
    "beta = 0.0001\n",
    "t_segment = [0, 1000]\n",
    "r = Rot.from_matrix([[0, -1, 0],\n",
    "                   [1, 0, 0],\n",
    "                   [0, 0, 1]])\n",
    "out = r.as_euler('zyx', degrees=True)\n",
    "dataSegment = data[t_segment[0]:t_segment[1]]\n",
    "ref_frame = data[39]\n",
    "\n",
    "dataSegment, rotations = rotateToNeutral(dataSegment[39], dataSegment, staticLandmarkIndices, True)\n",
    "for i in range(0, len(rotations)):\n",
    "    r = Rot.from_matrix(rotations[i])\n",
    "    rotations[i] = r.as_euler('zyx', degrees=True)\n",
    "rotations = np.array(rotations)\n",
    "plt.plot(rotations[:,0])\n",
    "rotations[:,0] = constrainedOneEuroFilter(rotations[:,0], t_segment, [39])\n",
    "rotations[:,1] = constrainedOneEuroFilter(rotations[:,1], t_segment, [39])\n",
    "rotations[:,2] = constrainedOneEuroFilter(rotations[:,2], t_segment, [39])\n",
    "plt.plot(rotations[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2dcc8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "Z_new = Z_state.reshape(Z.shape)\n",
    "plt.scatter(Z_new[i, :, 0], -Z_new[i, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c783804",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputToFile(rotation_output_path, np.array(rotations), fps, start, angle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1479a680",
   "metadata": {},
   "source": [
    "# 6. Particle filter implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ec68b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "def reweigh(samples, observation, cov, iteration=1):\n",
    "   # samples should be of shape [N_sample, dims]\n",
    "   # observation should be of shape [dims, ]\n",
    "    samples = np.expand_dims(samples, axis=2)\n",
    "    observation = np.expand_dims(np.expand_dims(observation, axis=0), axis=2)\n",
    "#     weight = samples @ observation[0] / (np.linalg.norm(observation[0:1],axis=1,keepdims=True) * np.linalg.norm(samples, axis=2,keepdims=True))\n",
    "#     weight = weight / weight.sum()\n",
    "    inv_cov = np.diag(1.0/(cov.diagonal()))\n",
    "    inv_cov = np.expand_dims(inv_cov, axis=0)\n",
    "#     print(inv_cov.shape)\n",
    "#     print((observation - samples).shape)\n",
    "    \n",
    "    prob = (observation - samples).transpose(0,2,1) @ inv_cov @ (observation - samples)\n",
    "    prob = prob / prob.sum()\n",
    "#     for i in range(0, iteration-1):\n",
    "#         weight = weight * weight\n",
    "#         weight = weight / weight.sum()\n",
    "    v_0 = (samples * prob).sum(axis=0)\n",
    "    return v_0.T \n",
    "def particle_filtering(Y, N_sample = 1000):\n",
    "    # the input Y should data that has already been iteratively filtered for rotation, scale and translation\n",
    "    # Y should be of shape [time_stamp, landmarkcount, 2]\n",
    "    start_time = time.time()\n",
    "    # center Y around mean\n",
    "    original_mean = Y.mean(axis=1, keepdims=True) \n",
    "    Z = Y - original_mean\n",
    "    # compute shape Z\n",
    "    T, N, k = Z.shape\n",
    "    Z_flat = Z.reshape(T, N*k, 1)\n",
    "    Z_state = np.zeros(Z_flat.shape)\n",
    "    Z_state[0] = Z_flat[0]\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    # find transition_covariance matrix\n",
    "    delta_Z_transition = Z_flat[1:] - Z_flat[:-1]\n",
    "    temp = delta_Z_transition  @ delta_Z_transition.transpose((0, 2, 1))\n",
    "    cov_z_t = (temp.sum(axis=0))/(T-1)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    delta_Z = Z_flat - moving_average(Z_flat, 10)\n",
    "    temp = delta_Z  @ delta_Z.transpose((0, 2, 1))\n",
    "    cov_z_n = (temp.sum(axis=0))/(T)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    for i in range(1, T):\n",
    "        prev_step = Z_state[i-1]\n",
    "        next_step_sample = np.random.multivariate_normal((prev_step)[:, 0], cov_z_n, N_sample)\n",
    "        Z_state[i] = reweigh(next_step_sample, Z_flat[i, :, 0], cov_z_n, 5).T\n",
    "    return Z_state.reshape(T, N, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d3458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = data[t_segment[0]:t_segment[1]]\n",
    "# compute shape Z\n",
    "Y = iterativeNormalization(Y, Y[0], staticLandmarkIndices, staticLandmarkIndices)\n",
    "Y_clean = particle_filtering(Y[:, keypointIndicies, 0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdf1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y_clean.mean(axis=2).mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430ebded",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_landmark(Y_clean, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee7cd8",
   "metadata": {},
   "source": [
    "# 7. Optical flow assisted landmark stabilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from utils.canonical_face import ObjLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d2820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lucas_kanade_method(video_path):\n",
    "    # Read the video \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Parameters for ShiTomasi corner detection\n",
    "    feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "\n",
    "    # Parameters for Lucas Kanade optical flow\n",
    "    lk_params = dict(\n",
    "        winSize=(9, 9),\n",
    "        maxLevel=2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
    "    )\n",
    "\n",
    "    # Create random colors\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "    # Take first frame and find corners in it\n",
    "    ret, old_frame = cap.read()\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "    # Create a mask image for drawing purposes\n",
    "    mask = np.zeros_like(old_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c89e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# cv2.calcOpticalFlowPyrLK\n",
    "\n",
    "lk_params = dict(\n",
    "    winSize=(15, 15),\n",
    "    maxLevel=3,\n",
    "    criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(videoPath)\n",
    "t = 0\n",
    "flow_data = []\n",
    "video_shape = []\n",
    "while cap.isOpened() and t < data.shape[0]:\n",
    "    # obtain the image frame\n",
    "    ret, frame_t1 = cap.read()\n",
    "    if frame_t1 is None:\n",
    "        break\n",
    "    # obtain the landmark frame:\n",
    "    lm_t1 = data[t-1, keypointIndicies].astype(np.float32)\n",
    "    \n",
    "    # un-normalize the position by multiplying by the frame size\n",
    "    lm_t1[:, 0] = lm_t1[:, 0] * frame_t1.shape[1]\n",
    "    lm_t1[:, 1] = lm_t1[:, 1] * frame_t1.shape[0]\n",
    "    ##### calculate optical flow #####\n",
    "    # convert to gray scale\n",
    "    frame_t1_gray = cv2.cvtColor(frame_t1, cv2.COLOR_BGR2GRAY)\n",
    "    lm_t1 = np.expand_dims(lm_t1, axis=1)[:, :, 0:2]\n",
    "    if t == 0:\n",
    "        video_shape = frame_t1_gray.shape\n",
    "        frame_t0_gray = frame_t1_gray.copy()\n",
    "        \n",
    "        lm_t1 = data[0, keypointIndicies].astype(np.float32)\n",
    "        # un-normalize the position by multiplying by the frame size\n",
    "        lm_t1[:, 0] = lm_t1[:, 0] * frame_t1.shape[1]\n",
    "        lm_t1[:, 1] = lm_t1[:, 1] * frame_t1.shape[0]\n",
    "        ##### calculate optical flow #####\n",
    "        # convert to gray scale\n",
    "        frame_t1_gray = cv2.cvtColor(frame_t1, cv2.COLOR_BGR2GRAY)\n",
    "        lm_t1 = np.expand_dims(lm_t1, axis=1)[:, :, 0:2]\n",
    "        p_t0 = lm_t1\n",
    "        \n",
    "        flow_data.append(p_t0[:, 0, :])\n",
    "        t = t+1\n",
    "        continue\n",
    "    p_t1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "        frame_t0_gray, frame_t1_gray, p_t0, None, **lk_params\n",
    "    )\n",
    "    # Select good points\n",
    "    good_new = p_t1[st == 1]\n",
    "    good_old = p_t0[st == 1]\n",
    "    flow_data.append(np.where(st==1, p_t1[:, 0, :], p_t0[:, 0, :]))\n",
    "    # display both, not important\n",
    "#     display_frame = np.zeros(frame_t1.shape)\n",
    "#     display_frame[:, :, 0] = frame_t1[:, :, 2]\n",
    "#     display_frame[:, :, 1] = frame_t1[:, :, 1]\n",
    "#     display_frame[:, :, 2] = frame_t1[:, :, 0]\n",
    "#     display_frame = display_frame/255.0\n",
    "#     plt.imshow(display_frame)\n",
    "#     plt.scatter(lm_t1[:, 0, 0], lm_t1[:, 0, 1], s=5)\n",
    "#     plt.scatter(good_new[:, 0], good_new[:, 1], s=5)\n",
    "#     plt.show()\n",
    "    #     cv2.imwrite(\"frame%d.jpg\" % count, frame)\n",
    "    t = t + 1\n",
    "    frame_t0_gray = frame_t1_gray.copy()\n",
    "    p_t0 = lm_t1\n",
    "   \n",
    "cap.release()\n",
    "# re-scale the optical flow data     \n",
    "flow_data = np.array(flow_data)\n",
    "flow_data[:, :, 0] = flow_data[:, :, 0] / video_shape[1]\n",
    "flow_data[:, :, 1] = flow_data[:, :, 1] / video_shape[0] \n",
    "flow_data_3d = data[:, keypointIndicies].copy()\n",
    "flow_data_3d[:, :, 0:2] = flow_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1b97d2",
   "metadata": {},
   "source": [
    "## quadratic_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83164e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1/2.2\n",
    "beta = 0.2/2.2\n",
    "gamma = 2/2.2\n",
    "lm_data_3d = data[:, keypointIndicies]\n",
    "flow_data_3d = flow_data_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84852e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qpsolvers import solve_qp\n",
    "# normalize to canonical direction\n",
    "face = ObjLoader(\"./data/canonical_face_model.obj\")\n",
    "lm_data_to_canonical = iterativeNormalization(data, face.vertices, staticLandmarkIndices, staticLandmarkIndices)[:, keypointIndicies]\n",
    "flow_data_3d_to_canonical = iterativeNormalization(flow_data_3d, face.vertices[keypointIndicies], np.arange(0, len(staticLandmarkIndices)), np.arange(0, len(staticLandmarkIndices)))\n",
    "\n",
    "lm_data_to_canonical = rotateToNeutral(face.vertices, data, staticLandmarkIndices)[:, keypointIndicies]\n",
    "# flow_data_3d_to_canonical = rotateToNeutral(face.vertices[keypointIndicies], flow_data_3d, np.arange(0, len(staticLandmarkIndices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283086d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lm_data_to_canonical.sum(axis=2).sum(axis=1))\n",
    "plt.plot(flow_data_3d_to_canonical.sum(axis=2).sum(axis=1))\n",
    "print(np.linalg.norm(flow_data_3d_to_canonical[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5cf777",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_landmakrs, N_dims = lm_data_to_canonical[0].shape\n",
    "qp_sols = [lm_data_to_canonical[0].reshape(N_landmakrs*N_dims)]\n",
    "for i in range(1, lm_data_to_canonical.shape[0]):\n",
    "    L_lm_t = lm_data_to_canonical[i].reshape(N_landmakrs*N_dims)\n",
    "    L_fl_t = flow_data_3d_to_canonical[i].reshape(N_landmakrs*N_dims)\n",
    "    L_lm_prev = qp_sols[-1]/2\n",
    "    P = (alpha + beta + gamma) * np.eye(N_landmakrs*N_dims)\n",
    "    q = -2*(alpha * L_lm_t + beta * L_fl_t + gamma * L_lm_prev)    \n",
    "    L = solve_qp(P, q, initvals=L_lm_t)\n",
    "    qp_sols.append(L)\n",
    "L_stabilized = np.array(qp_sols)\n",
    "L_stabilized = L_stabilized.reshape((L_stabilized.shape[0], N_landmakrs, N_dims))\n",
    "plt.plot(L_stabilized.sum(axis=2).sum(axis=1)/2)\n",
    "plt.plot(lm_data_to_canonical.sum(axis=2).sum(axis=1))\n",
    "plt.plot(flow_data_3d_to_canonical.sum(axis=2).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e6f58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L_stabilized[:, :, 1] = -L_stabilized[:, :, 1]\n",
    "display_landmark(L_stabilized, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecdd780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = -1\n",
    "plt.scatter(flow_data_3d_to_canonical[i, np.arange(0, len(staticLandmarkIndices)), 0], -flow_data_3d_to_canonical[i, np.arange(0, len(staticLandmarkIndices)), 1])\n",
    "plt.scatter(face.vertices[staticLandmarkIndices][:,0], face.vertices[staticLandmarkIndices][:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12d49ea",
   "metadata": {},
   "source": [
    "# 8. Face Normalization with predicted rotation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa61e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.canonical_face import ObjLoader\n",
    "import matplotlib.path as mpltPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bbdc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data = cv2.VideoCapture(videoPath)\n",
    "lm_data = np.load(lmPath)\n",
    "\n",
    "ret, frame_t = video_data.read()\n",
    "vertex_list = []\n",
    "for x in range(0, frame_t.shape[0]):\n",
    "    for y in range(0, frame_t.shape[1]):\n",
    "        vertex_list.append([x, y])\n",
    "\n",
    "frame_t = cv2.cvtColor(frame_t, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(frame)\n",
    "boundary_lm_t = lm_data[0, full_boundary_anchor, 0:2]\n",
    "boundary_lm_t[:, 0] = boundary_lm_t[:, 0] * frame_t.shape[1]\n",
    "boundary_lm_t[:, 1] = boundary_lm_t[:, 1] * frame_t.shape[0]\n",
    "# plt.scatter(boundary_lm_t[:, 0] * frame_t.shape[1], boundary_lm_t[:,1] * frame_t.shape[0])\n",
    "\n",
    "# check for points that are inside the face\n",
    "polyCurve = mpltPath.Path(boundary_lm_t)\n",
    "contained_set = polyCurve.contains_points(vertex_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for i in range(0, len(contained_set)):\n",
    "    if contained_set[i]:\n",
    "        indexes.append(vertex_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4107a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = ObjLoader(\"./data/canonical_face_model.obj\")\n",
    "lm_data_to_canonical = iterativeNormalization(lm_data, face.vertices, staticLandmarkIndices, staticLandmarkIndices)[:, keypointIndicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
